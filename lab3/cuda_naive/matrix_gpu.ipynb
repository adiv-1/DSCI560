{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85338f1d",
   "metadata": {},
   "source": [
    "## Task 2 - Naive CUDA Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89fc6e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 27 06:27:57 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   49C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "050894cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing matrix_gpu.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile matrix_gpu.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void matrixMultiplyGPU(float *A, float *B, float *C, int N) {\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (row < N && col < N) {\n",
    "        float sum = 0.0f;\n",
    "        for (int k = 0; k < N; k++) {\n",
    "            sum += A[row * N + k] * B[k * N + col];\n",
    "        }\n",
    "        C[row * N + col] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv) {\n",
    "    int N = 512;\n",
    "    if (argc > 1) {\n",
    "        N = atoi(argv[1]);\n",
    "    }\n",
    "\n",
    "    size_t matrix_size = N * N * sizeof(float);\n",
    "    \n",
    "    float *host_A = (float *)malloc(matrix_size);\n",
    "    float *host_B = (float *)malloc(matrix_size);\n",
    "    float *host_C = (float *)malloc(matrix_size);\n",
    "    \n",
    "    for (int i = 0; i < N * N; i++) {\n",
    "        host_A[i] = rand() % 100 / 100.0f;\n",
    "        host_B[i] = rand() % 100 / 100.0f;\n",
    "    }    \n",
    "    float *device_A;\n",
    "    float *device_B;\n",
    "    float *device_C;\n",
    "    \n",
    "    cudaMalloc((void**)&device_A, matrix_size);\n",
    "    cudaMalloc((void**)&device_B, matrix_size);\n",
    "    cudaMalloc((void**)&device_C, matrix_size);\n",
    "    \n",
    "    cudaMemcpy(device_A, host_A, matrix_size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(device_B, host_B, matrix_size, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    dim3 threadsPerBlock(16, 16);\n",
    "    \n",
    "    // Calculate how many blocks we need\n",
    "    int num_blocks = (N + 15) / 16;\n",
    "    dim3 numBlocks(num_blocks, num_blocks);\n",
    "    \n",
    "    printf(\"Using %d x %d blocks with 16 x 16 threads per block\\n\", num_blocks, num_blocks);\n",
    "    \n",
    "    cudaEvent_t start_event, stop_event;\n",
    "    cudaEventCreate(&start_event);\n",
    "    cudaEventCreate(&stop_event);\n",
    "    \n",
    "    //start time\n",
    "    cudaEventRecord(start_event);    \n",
    "    matrixMultiplyGPU<<<numBlocks, threadsPerBlock>>>(device_A, device_B, device_C, N);\n",
    "    cudaEventRecord(stop_event); //stop time\n",
    "    cudaEventSynchronize(stop_event);\n",
    "    \n",
    "    float milliseconds = 0;\n",
    "    cudaEventElapsedTime(&milliseconds, start_event, stop_event);\n",
    "    \n",
    "    printf(\"Naive CUDA execution time (N=%d): %f ms\\n\", N, milliseconds);\n",
    "    printf(\"In %f seconds\\n\", milliseconds / 1000.0f);\n",
    "    \n",
    "    cudaMemcpy(host_C, device_C, matrix_size, cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    volatile float prevent_optimization = host_C[0];\n",
    "    \n",
    "    cudaFree(device_A);\n",
    "    cudaFree(device_B);\n",
    "    cudaFree(device_C);\n",
    "    \n",
    "    free(host_A);\n",
    "    free(host_B);\n",
    "    free(host_C);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35a3b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc matrix_gpu.cu -o matrix_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01966c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 32 x 32 blocks with 16 x 16 threads per block\n",
      "Naive CUDA execution time (N=512): 7.336448 ms\n",
      "In 0.007336 seconds\n",
      "Using 64 x 64 blocks with 16 x 16 threads per block\n",
      "Naive CUDA execution time (N=1024): 7.443808 ms\n",
      "In 0.007444 seconds\n",
      "Using 128 x 128 blocks with 16 x 16 threads per block\n",
      "Naive CUDA execution time (N=2048): 7.527648 ms\n",
      "In 0.007528 seconds\n"
     ]
    }
   ],
   "source": [
    "!./matrix_gpu 512\n",
    "!./matrix_gpu 1024\n",
    "!./matrix_gpu 2048"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
