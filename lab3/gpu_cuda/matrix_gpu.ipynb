{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85338f1d",
   "metadata": {},
   "source": [
    "## Task 2 - Naive CUDA Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050894cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting matrix_gpu_naive.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile matrix_gpu_naive.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void matrixMultiplyGPU(float *A, float *B, float *C, int N) {\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (row < N && col < N) {\n",
    "        float sum = 0.0f;\n",
    "        for (int k = 0; k < N; k++) {\n",
    "            sum += A[row * N + k] * B[k * N + col];\n",
    "        }\n",
    "        C[row * N + col] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv) {\n",
    "    int N = 512;\n",
    "    if (argc > 1) {\n",
    "        N = atoi(argv[1]);\n",
    "    }\n",
    "\n",
    "    size_t matrix_size = N * N * sizeof(float);\n",
    "    \n",
    "    float *host_A = (float *)malloc(matrix_size);\n",
    "    float *host_B = (float *)malloc(matrix_size);\n",
    "    float *host_C = (float *)malloc(matrix_size);\n",
    "    \n",
    "    for (int i = 0; i < N * N; i++) {\n",
    "        host_A[i] = rand() % 100 / 100.0f;\n",
    "        host_B[i] = rand() % 100 / 100.0f;\n",
    "    }    \n",
    "    float *device_A;\n",
    "    float *device_B;\n",
    "    float *device_C;\n",
    "    \n",
    "    cudaMalloc((void**)&device_A, matrix_size);\n",
    "    cudaMalloc((void**)&device_B, matrix_size);\n",
    "    cudaMalloc((void**)&device_C, matrix_size);\n",
    "    \n",
    "    cudaMemcpy(device_A, host_A, matrix_size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(device_B, host_B, matrix_size, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    dim3 threadsPerBlock(16, 16);\n",
    "    \n",
    "    // Calculate how many blocks we need\n",
    "    int num_blocks = (N + 15) / 16;\n",
    "    dim3 numBlocks(num_blocks, num_blocks);\n",
    "    \n",
    "    printf(\"Using %d x %d blocks with 16 x 16 threads per block\\n\", num_blocks, num_blocks);\n",
    "    \n",
    "    cudaEvent_t start_event, stop_event;\n",
    "    cudaEventCreate(&start_event);\n",
    "    cudaEventCreate(&stop_event);\n",
    "    \n",
    "    //start time\n",
    "    cudaEventRecord(start_event);    \n",
    "    matrixMultiplyGPU<<<numBlocks, threadsPerBlock>>>(device_A, device_B, device_C, N);\n",
    "    cudaEventRecord(stop_event); //stop time\n",
    "    cudaEventSynchronize(stop_event);\n",
    "    \n",
    "    float milliseconds = 0;\n",
    "    cudaEventElapsedTime(&milliseconds, start_event, stop_event);\n",
    "    \n",
    "    printf(\"Naive CUDA execution time (N=%d): %f ms\\n\", N, milliseconds);\n",
    "    printf(\"In %f seconds\\n\", milliseconds / 1000.0f);\n",
    "    \n",
    "    cudaMemcpy(host_C, device_C, matrix_size, cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    volatile float prevent_optimization = host_C[0];\n",
    "    \n",
    "    cudaFree(device_A);\n",
    "    cudaFree(device_B);\n",
    "    cudaFree(device_C);\n",
    "    \n",
    "    free(host_A);\n",
    "    free(host_B);\n",
    "    free(host_C);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f601a6",
   "metadata": {},
   "source": [
    "## Task 3 - Tiled CUDA code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017d8dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jan 31 03:50:51 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   47C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb287b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
      "Cuda compilation tools, release 12.5, V12.5.82\n",
      "Build cuda_12.5.r12.5/compiler.34385749_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45a00b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc matrix_gpu_naive.cu -o matrix_gpu_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2abe4013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 32 x 32 blocks with 16 x 16 threads per block\n",
      "Naive CUDA execution time (N=512): 7.286528 ms\n",
      "In 0.007287 seconds\n",
      "Using 64 x 64 blocks with 16 x 16 threads per block\n",
      "Naive CUDA execution time (N=1024): 7.479136 ms\n",
      "In 0.007479 seconds\n",
      "Using 128 x 128 blocks with 16 x 16 threads per block\n",
      "Naive CUDA execution time (N=2048): 7.086944 ms\n",
      "In 0.007087 seconds\n",
      "Using 256 x 256 blocks with 16 x 16 threads per block\n",
      "Naive CUDA execution time (N=4096): 7.450912 ms\n",
      "In 0.007451 seconds\n",
      "Using 512 x 512 blocks with 16 x 16 threads per block\n",
      "Naive CUDA execution time (N=8192): 7.147232 ms\n",
      "In 0.007147 seconds\n"
     ]
    }
   ],
   "source": [
    "!./matrix_gpu_naive 512\n",
    "!./matrix_gpu_naive 1024\n",
    "!./matrix_gpu_naive 2048\n",
    "!./matrix_gpu_naive 4096\n",
    "!./matrix_gpu_naive 8192"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cf5c47",
   "metadata": {},
   "source": [
    "## Task 4 - Optimizing CUDA Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5172ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting matrix_gpu_tiled.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile matrix_gpu_tiled.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda_runtime.h>\n",
    "#define TILE_WIDTH 16\n",
    "\n",
    "__global__ void matrixMultiplyTiled(float *A, float *B, float *C, int N) {\n",
    "    __shared__ float ds_A[TILE_WIDTH][TILE_WIDTH];\n",
    "    __shared__ float ds_B[TILE_WIDTH][TILE_WIDTH];\n",
    "\n",
    "    int bx = blockIdx.x;\n",
    "    int by = blockIdx.y;\n",
    "    int tx = threadIdx.x;\n",
    "    int ty = threadIdx.y;\n",
    "\n",
    "    int Row = by * TILE_WIDTH + ty;\n",
    "    int Col = bx * TILE_WIDTH + tx;\n",
    "\n",
    "    float Pvalue = 0.0f;\n",
    "\n",
    "    for (int m = 0; m < (N + TILE_WIDTH - 1) / TILE_WIDTH; ++m) {\n",
    "\n",
    "        if (Row < N && (m * TILE_WIDTH + tx) < N)\n",
    "            ds_A[ty][tx] = A[Row * N + m * TILE_WIDTH + tx];\n",
    "        else\n",
    "            ds_A[ty][tx] = 0.0f;\n",
    "\n",
    "        if (Col < N && (m * TILE_WIDTH + ty) < N)\n",
    "            ds_B[ty][tx] = B[(m * TILE_WIDTH + ty) * N + Col];\n",
    "        else\n",
    "            ds_B[ty][tx] = 0.0f;\n",
    "\n",
    "        __syncthreads();\n",
    "\n",
    "        for (int k = 0; k < TILE_WIDTH; ++k)\n",
    "            Pvalue += ds_A[ty][k] * ds_B[k][tx];\n",
    "\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    if (Row < N && Col < N)\n",
    "        C[Row * N + Col] = Pvalue;\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv) {\n",
    "    int N = 512;\n",
    "    if (argc > 1) {\n",
    "        N = atoi(argv[1]);\n",
    "    }\n",
    "\n",
    "    size_t matrix_size = N * N * sizeof(float);\n",
    "    \n",
    "    float *host_A = (float *)malloc(matrix_size);\n",
    "    float *host_B = (float *)malloc(matrix_size);\n",
    "    float *host_C = (float *)malloc(matrix_size);\n",
    "    \n",
    "    for (int i = 0; i < N * N; i++) {\n",
    "        host_A[i] = rand() % 100 / 100.0f;\n",
    "        host_B[i] = rand() % 100 / 100.0f;\n",
    "    }    \n",
    "    float *device_A;\n",
    "    float *device_B;\n",
    "    float *device_C;\n",
    "    \n",
    "    cudaMalloc((void**)&device_A, matrix_size);\n",
    "    cudaMalloc((void**)&device_B, matrix_size);\n",
    "    cudaMalloc((void**)&device_C, matrix_size);\n",
    "    \n",
    "    cudaMemcpy(device_A, host_A, matrix_size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(device_B, host_B, matrix_size, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    dim3 threadsPerBlock(16, 16);\n",
    "    \n",
    "    // Calculate how many blocks we need\n",
    "    int num_blocks = (N + 15) / 16;\n",
    "    dim3 numBlocks(num_blocks, num_blocks);\n",
    "    \n",
    "    printf(\"Using %d x %d blocks with 16 x 16 threads per block\\n\", num_blocks, num_blocks);\n",
    "    \n",
    "    cudaEvent_t start_event, stop_event;\n",
    "    cudaEventCreate(&start_event);\n",
    "    cudaEventCreate(&stop_event);\n",
    "    \n",
    "    //start time\n",
    "    cudaEventRecord(start_event);    \n",
    "    matrixMultiplyTiled<<<numBlocks, threadsPerBlock>>>(device_A, device_B, device_C, N);\n",
    "    cudaEventRecord(stop_event); //stop time\n",
    "    cudaEventSynchronize(stop_event);\n",
    "    \n",
    "    float milliseconds = 0;\n",
    "    cudaEventElapsedTime(&milliseconds, start_event, stop_event);\n",
    "    \n",
    "    printf(\"Tiled CUDA execution time (N=%d): %f ms\\n\", N, milliseconds);\n",
    "    printf(\"In %f seconds\\n\", milliseconds / 1000.0f);\n",
    "    \n",
    "    cudaMemcpy(host_C, device_C, matrix_size, cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    volatile float prevent_optimization = host_C[0];\n",
    "    \n",
    "    cudaFree(device_A);\n",
    "    cudaFree(device_B);\n",
    "    cudaFree(device_C);\n",
    "    \n",
    "    free(host_A);\n",
    "    free(host_B);\n",
    "    free(host_C);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5339f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc matrix_gpu_tiled.cu -o matrix_gpu_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b97d37c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 32 x 32 blocks with 16 x 16 threads per block\n",
      "Tiled CUDA execution time (N=512): 7.083840 ms\n",
      "In 0.007084 seconds\n",
      "Using 64 x 64 blocks with 16 x 16 threads per block\n",
      "Tiled CUDA execution time (N=1024): 7.318496 ms\n",
      "In 0.007318 seconds\n",
      "Using 128 x 128 blocks with 16 x 16 threads per block\n",
      "Tiled CUDA execution time (N=2048): 7.219872 ms\n",
      "In 0.007220 seconds\n",
      "Using 256 x 256 blocks with 16 x 16 threads per block\n",
      "Tiled CUDA execution time (N=4096): 7.092448 ms\n",
      "In 0.007092 seconds\n",
      "Using 512 x 512 blocks with 16 x 16 threads per block\n",
      "Tiled CUDA execution time (N=8192): 7.253760 ms\n",
      "In 0.007254 seconds\n"
     ]
    }
   ],
   "source": [
    "!./matrix_gpu_tiled 512\n",
    "!./matrix_gpu_tiled 1024\n",
    "!./matrix_gpu_tiled 2048\n",
    "!./matrix_gpu_tiled 4096\n",
    "!./matrix_gpu_tiled 8192"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2417314",
   "metadata": {},
   "source": [
    "## Task 5 - Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbd1d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "python_512 = 7.81 * 1000\n",
    "python_1024 = 65.46 * 1000\n",
    "python_2048 = 839.49 * 1000\n",
    "\n",
    "cpu_512  = 0.49 * 1000\n",
    "cpu_1024 = 3.71 * 1000\n",
    "cpu_2048 = 37.63 * 1000\n",
    "\n",
    "naive_512  = 0.0125 * 1000\n",
    "naive_1024 = 0.0109 * 1000\n",
    "naive_2048 = 0.0107 * 1000\n",
    "\n",
    "tiled_512  = 0.0088 * 1000\n",
    "tiled_1024 = 0.0106 * 1000\n",
    "tiled_2048 = 0.0109 * 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a60873ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup_naive_512  = cpu_512  / naive_512\n",
    "speedup_naive_1024 = cpu_1024 / naive_1024\n",
    "speedup_naive_2048 = cpu_2048 / naive_2048\n",
    "\n",
    "speedup_tiled_512  = cpu_512  / tiled_512\n",
    "speedup_tiled_1024 = cpu_1024 / tiled_1024\n",
    "speedup_tiled_2048 = cpu_2048 / tiled_2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f257dae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4b1bb4c7-8ab3-4855-b2b0-811e6df67ae3\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Implementation</th>\n",
       "      <th>N = 512</th>\n",
       "      <th>N = 1024</th>\n",
       "      <th>N = 2048</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPU Time (ms)</td>\n",
       "      <td>490.00</td>\n",
       "      <td>3710.00</td>\n",
       "      <td>37630.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive CUDA Time (ms)</td>\n",
       "      <td>12.50</td>\n",
       "      <td>10.90</td>\n",
       "      <td>10.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive CUDA Speedup</td>\n",
       "      <td>39.20</td>\n",
       "      <td>340.37</td>\n",
       "      <td>3516.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tiled CUDA Time (ms)</td>\n",
       "      <td>8.80</td>\n",
       "      <td>10.60</td>\n",
       "      <td>10.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tiled CUDA Speedup</td>\n",
       "      <td>55.68</td>\n",
       "      <td>350.00</td>\n",
       "      <td>3452.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b1bb4c7-8ab3-4855-b2b0-811e6df67ae3')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-4b1bb4c7-8ab3-4855-b2b0-811e6df67ae3 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-4b1bb4c7-8ab3-4855-b2b0-811e6df67ae3');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         Implementation  N = 512  N = 1024  N = 2048\n",
       "0         CPU Time (ms)   490.00   3710.00  37630.00\n",
       "1  Naive CUDA Time (ms)    12.50     10.90     10.70\n",
       "2    Naive CUDA Speedup    39.20    340.37   3516.82\n",
       "3  Tiled CUDA Time (ms)     8.80     10.60     10.90\n",
       "4    Tiled CUDA Speedup    55.68    350.00   3452.29"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Implementation\": [\n",
    "        \"CPU Time (ms)\",\n",
    "        \"Naive CUDA Time (ms)\",\n",
    "        \"Naive CUDA Speedup\",\n",
    "        \"Tiled CUDA Time (ms)\",\n",
    "        \"Tiled CUDA Speedup\"\n",
    "    ],\n",
    "    \"N = 512\": [\n",
    "        cpu_512,\n",
    "        naive_512,\n",
    "        speedup_naive_512,\n",
    "        tiled_512,\n",
    "        speedup_tiled_512\n",
    "    ],\n",
    "    \"N = 1024\": [\n",
    "        cpu_1024,\n",
    "        naive_1024,\n",
    "        speedup_naive_1024,\n",
    "        tiled_1024,\n",
    "        speedup_tiled_1024\n",
    "    ],\n",
    "    \"N = 2048\": [\n",
    "        cpu_2048,\n",
    "        naive_2048,\n",
    "        speedup_naive_2048,\n",
    "        tiled_2048,\n",
    "        speedup_tiled_2048\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c55054",
   "metadata": {},
   "source": [
    "## Step 6 - Using cuBLAS Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77444d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting matrix_gpu_cublas.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile matrix_gpu_cublas.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <cublas_v2.h>\n",
    "\n",
    "int main(int argc, char **argv) {\n",
    "    int N;\n",
    "    if (argc > 1) {\n",
    "        N = atoi(argv[1]);\n",
    "    } else {\n",
    "        N = 1024; // default size\n",
    "    }\n",
    "    \n",
    "    size_t size = N * N * sizeof(float);\n",
    "\n",
    "    float *h_A = (float *)malloc(size);\n",
    "    float *h_B = (float *)malloc(size);\n",
    "    float *h_C = (float *)malloc(size);\n",
    "\n",
    "    for (int i = 0; i < N * N; i++) {\n",
    "        h_A[i] = rand() % 100 / 100.0f;\n",
    "    }\n",
    "    \n",
    "    for (int i = 0; i < N * N; i++) {\n",
    "        h_B[i] = rand() % 100 / 100.0f;\n",
    "    }\n",
    "\n",
    "    float *d_A;\n",
    "    float *d_B;\n",
    "    float *d_C;\n",
    "    \n",
    "    cudaMalloc((void**)&d_A, size);\n",
    "    cudaMalloc((void**)&d_B, size);\n",
    "    cudaMalloc((void**)&d_C, size);\n",
    "\n",
    "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    cublasHandle_t handle;\n",
    "    cublasCreate(&handle);\n",
    "\n",
    "    float alpha = 1.0f;\n",
    "    float beta  = 0.0f;\n",
    "\n",
    "    cudaEvent_t start;\n",
    "    cudaEvent_t stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    cudaEventRecord(start);\n",
    "    cublasSgemm(handle,\n",
    "                CUBLAS_OP_N, CUBLAS_OP_N,\n",
    "                N, N, N,\n",
    "                &alpha,\n",
    "                d_B, N,\n",
    "                d_A, N,\n",
    "                &beta,\n",
    "                d_C, N);\n",
    "\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    float ms;\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    printf(\"cuBLAS SGEMM time (N=%d): %f ms\\n\", N, ms);\n",
    "\n",
    "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);   \n",
    "    volatile float sink = h_C[0];\n",
    "\n",
    "    cublasDestroy(handle);\n",
    "    \n",
    "    cudaFree(d_A);\n",
    "    cudaFree(d_B);\n",
    "    cudaFree(d_C);\n",
    "\n",
    "    free(h_A);\n",
    "    free(h_B);\n",
    "    free(h_C);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08c6bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc matrix_gpu_tiled.cu -o matrix_gpu_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d9f434f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 32 x 32 blocks with 16 x 16 threads per block\n",
      "Tiled CUDA execution time (N=512): 7.873824 ms\n",
      "In 0.007874 seconds\n",
      "Using 64 x 64 blocks with 16 x 16 threads per block\n",
      "Tiled CUDA execution time (N=1024): 7.152192 ms\n",
      "In 0.007152 seconds\n",
      "Using 128 x 128 blocks with 16 x 16 threads per block\n",
      "Tiled CUDA execution time (N=2048): 7.178624 ms\n",
      "In 0.007179 seconds\n"
     ]
    }
   ],
   "source": [
    "!./matrix_gpu_tiled 512\n",
    "!./matrix_gpu_tiled 1024\n",
    "!./matrix_gpu_tiled 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bedabf0",
   "metadata": {},
   "source": [
    "## Step 7 - Creating a Shared Library and Using it in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4234b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting matrix_lib.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile matrix_lib.cu\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdio.h>\n",
    "#define TILE_WIDTH 16\n",
    "\n",
    "__global__ void matrixMultiplyTiled(float *A, float *B, float *C, int N) {\n",
    "    __shared__ float ds_A[TILE_WIDTH][TILE_WIDTH];\n",
    "    __shared__ float ds_B[TILE_WIDTH][TILE_WIDTH];\n",
    "\n",
    "    int tx = threadIdx.x;\n",
    "    int ty = threadIdx.y;\n",
    "    \n",
    "    int Row = blockIdx.y * TILE_WIDTH + ty;\n",
    "    int Col = blockIdx.x * TILE_WIDTH + tx;\n",
    "\n",
    "    float Pvalue = 0.0f;\n",
    "\n",
    "    int numTiles = (N + TILE_WIDTH - 1) / TILE_WIDTH;\n",
    "    for (int m = 0; m < numTiles; ++m) {\n",
    "        int aCol = m * TILE_WIDTH + tx;\n",
    "        if (Row < N && aCol < N) {\n",
    "            ds_A[ty][tx] = A[Row * N + aCol];\n",
    "        } else {\n",
    "            ds_A[ty][tx] = 0.0f;\n",
    "        }\n",
    "\n",
    "        int bRow = m * TILE_WIDTH + ty;\n",
    "        if (Col < N && bRow < N) {\n",
    "            ds_B[ty][tx] = B[bRow * N + Col];\n",
    "        } else {\n",
    "            ds_B[ty][tx] = 0.0f;\n",
    "        }\n",
    "\n",
    "        __syncthreads();\n",
    "\n",
    "        for (int k = 0; k < TILE_WIDTH; ++k) {\n",
    "            Pvalue += ds_A[ty][k] * ds_B[k][tx];\n",
    "        }\n",
    "\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    if (Row < N && Col < N) {\n",
    "        C[Row * N + Col] = Pvalue;\n",
    "    }\n",
    "}\n",
    "\n",
    "extern \"C\" void gpu_matrix_multiply(float *h_A, float *h_B, float *h_C, int N) {\n",
    "    size_t size = N * N * sizeof(float);\n",
    "\n",
    "    float *d_A;\n",
    "    float *d_B;\n",
    "    float *d_C;\n",
    "    \n",
    "    cudaMalloc((void**)&d_A, size);\n",
    "    cudaMalloc((void**)&d_B, size);\n",
    "    cudaMalloc((void**)&d_C, size);\n",
    "\n",
    "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 block(TILE_WIDTH, TILE_WIDTH);\n",
    "    \n",
    "    int numBlocksX = (N + TILE_WIDTH - 1) / TILE_WIDTH;\n",
    "    int numBlocksY = (N + TILE_WIDTH - 1) / TILE_WIDTH;\n",
    "    dim3 grid(numBlocksX, numBlocksY);\n",
    "\n",
    "    matrixMultiplyTiled<<<grid, block>>>(d_A, d_B, d_C, N);\n",
    "    cudaDeviceSynchronize();\n",
    "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    cudaFree(d_A);\n",
    "    cudaFree(d_B);\n",
    "    cudaFree(d_C);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1be17d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -Xcompiler -fPIC -shared matrix_lib.cu -o libmatrix.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48ed672a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with matrix size N = 512\n",
      "CUDA library time (N=512): 128.7131 milliseconds\n",
      "\n",
      "Testing with matrix size N = 1024\n",
      "CUDA library time (N=1024): 4.2226 milliseconds\n",
      "\n",
      "Testing with matrix size N = 2048\n",
      "CUDA library time (N=2048): 21.9338 milliseconds\n",
      "\n",
      "Testing with matrix size N = 4096\n",
      "CUDA library time (N=4096): 87.1000 milliseconds\n",
      "\n",
      "Testing with matrix size N = 8192\n",
      "CUDA library time (N=8192): 286.8943 milliseconds\n"
     ]
    }
   ],
   "source": [
    "import ctypes\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "lib = ctypes.cdll.LoadLibrary(\"./libmatrix.so\")\n",
    "lib.gpu_matrix_multiply.argtypes = [\n",
    "    np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
    "    np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
    "    np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
    "    ctypes.c_int\n",
    "]\n",
    "\n",
    "N = 512\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"\\nTesting with matrix size N = {N}\")\n",
    "    \n",
    "    A = np.random.rand(N, N).astype(np.float32)\n",
    "    B = np.random.rand(N, N).astype(np.float32)\n",
    "    C = np.zeros((N, N), dtype=np.float32)\n",
    "    \n",
    "    start = time.time()\n",
    "    lib.gpu_matrix_multiply(A.ravel(), B.ravel(), C.ravel(), N)\n",
    "    end = time.time()\n",
    "    elapsed_time = end - start\n",
    "    \n",
    "    print(f\"CUDA library time (N={N}): {elapsed_time * 1000:.4f} milliseconds\")\n",
    "    \n",
    "    N = N * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5bccb0",
   "metadata": {},
   "source": [
    "## Step 8 - Adding Custom Functions to the Shared Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa705c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting conv_gpu.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile conv_gpu.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void convolution2D_GPU(\n",
    "    unsigned char *image,\n",
    "    int *kernel,\n",
    "    int *output,\n",
    "    int width,\n",
    "    int height\n",
    ") {\n",
    "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "\n",
    "    if (x >= width || y >= height) return;\n",
    "\n",
    "    int sum = 0;\n",
    "    int k = 1;  // 3x3 kernel radius\n",
    "\n",
    "    for (int ky = -k; ky <= k; ky++) {\n",
    "        for (int kx = -k; kx <= k; kx++) {\n",
    "            int ix = x + kx;\n",
    "            int iy = y + ky;\n",
    "            if (ix >= 0 && ix < width && iy >= 0 && iy < height) {\n",
    "                int pixel = image[iy * width + ix];\n",
    "                int weight = kernel[(ky + k) * 3 + (kx + k)];\n",
    "                sum += pixel * weight;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    output[y * width + x] = sum;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int width = 512;\n",
    "    int height = 512;\n",
    "    size_t img_size = width * height * sizeof(unsigned char);\n",
    "    size_t out_size = width * height * sizeof(int);\n",
    "\n",
    "    unsigned char *h_img = (unsigned char*)malloc(img_size);\n",
    "    int *h_out = (int*)malloc(out_size);\n",
    "\n",
    "    int h_kernel[9] = {\n",
    "        -1, -1, -1,\n",
    "        -1,  8, -1,\n",
    "        -1, -1, -1\n",
    "    };\n",
    "\n",
    "    for (int i = 0; i < width * height; i++)\n",
    "        h_img[i] = rand() % 256;\n",
    "\n",
    "    unsigned char *d_img;\n",
    "    int *d_kernel, *d_out;\n",
    "\n",
    "    cudaMalloc(&d_img, img_size);\n",
    "    cudaMalloc(&d_kernel, 9 * sizeof(int));\n",
    "    cudaMalloc(&d_out, out_size);\n",
    "\n",
    "    cudaMemcpy(d_img, h_img, img_size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_kernel, h_kernel, 9 * sizeof(int), cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 block(16, 16);\n",
    "    dim3 grid((width + 15) / 16, (height + 15) / 16);\n",
    "\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "\n",
    "    cudaEventRecord(start);\n",
    "    convolution2D_GPU<<<grid, block>>>(d_img, d_kernel, d_out, width, height);\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "\n",
    "    float ms;\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    printf(\"CUDA convolution time: %f ms\\n\", ms);\n",
    "\n",
    "    cudaMemcpy(h_out, d_out, out_size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    cudaFree(d_img);\n",
    "    cudaFree(d_kernel);\n",
    "    cudaFree(d_out);\n",
    "    free(h_img);\n",
    "    free(h_out);\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c88f175b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc conv_gpu.cu -o conv_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d989833d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA convolution time: 7.416800 ms\n"
     ]
    }
   ],
   "source": [
    "!./conv_gpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
