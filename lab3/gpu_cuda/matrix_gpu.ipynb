{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85338f1d",
   "metadata": {},
   "source": [
    "## Task 2 - Naive CUDA Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "050894cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting matrix_gpu_naive.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile matrix_gpu_naive.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "__global__ void matmul(float *a, float *b, float *c, int n) {\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    if (row < n && col < n) {\n",
    "        float sum = 0.0f;\n",
    "        for (int k = 0; k < n; k++) {\n",
    "            sum += a[row * n + k] * b[k * n + col];\n",
    "        }\n",
    "        c[row * n + col] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv) {\n",
    "    int n = 512;\n",
    "    if (argc > 1) {\n",
    "        n = atoi(argv[1]);\n",
    "    }\n",
    "\n",
    "    printf(\"Matrix size: %d x %d\\n\", n, n);\n",
    "\n",
    "    size_t size = n * n * sizeof(float);\n",
    "    \n",
    "    float *a = (float *)malloc(size);\n",
    "    float *b = (float *)malloc(size);\n",
    "    float *c = (float *)malloc(size);\n",
    "    \n",
    "    for (int i = 0; i < n * n; i++) {\n",
    "        a[i] = rand() % 100 / 100.0f;\n",
    "        b[i] = rand() % 100 / 100.0f;\n",
    "    }\n",
    "    \n",
    "    float *d_a, *d_b, *d_c;\n",
    "    \n",
    "    cudaMalloc(&d_a, size);\n",
    "    cudaMalloc(&d_b, size);\n",
    "    cudaMalloc(&d_c, size);\n",
    "    \n",
    "    cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    dim3 threads(16, 16);\n",
    "    dim3 blocks((n + 15) / 16, (n + 15) / 16);\n",
    "    \n",
    "    struct timeval t1, t2;\n",
    "    \n",
    "    gettimeofday(&t1, 0);\n",
    "    matmul<<<blocks, threads>>>(d_a, d_b, d_c, n);\n",
    "    cudaDeviceSynchronize();\n",
    "    gettimeofday(&t2, 0);\n",
    "    \n",
    "    double time = (1000000.0 * (t2.tv_sec - t1.tv_sec) + t2.tv_usec - t1.tv_usec) / 1000.0;\n",
    "    \n",
    "    printf(\"Time: %f ms\\n\", time);\n",
    "    \n",
    "    cudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_c);\n",
    "    \n",
    "    free(a);\n",
    "    free(b);\n",
    "    free(c);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f601a6",
   "metadata": {},
   "source": [
    "## Task 3 - Tiled CUDA code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "017d8dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb  1 03:29:51 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   38C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb287b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
      "Cuda compilation tools, release 12.5, V12.5.82\n",
      "Build cuda_12.5.r12.5/compiler.34385749_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45a00b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc matrix_gpu_naive.cu -o matrix_gpu_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2abe4013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix size: 512 x 512\n",
      "Time: 7.298000 ms\n",
      "Matrix size: 1024 x 1024\n",
      "Time: 7.330000 ms\n",
      "Matrix size: 2048 x 2048\n",
      "Time: 7.378000 ms\n",
      "Matrix size: 4096 x 4096\n",
      "Time: 7.217000 ms\n",
      "Matrix size: 8192 x 8192\n",
      "Time: 7.429000 ms\n",
      "Matrix size: 16384 x 16384\n",
      "Time: 7.377000 ms\n"
     ]
    }
   ],
   "source": [
    "!./matrix_gpu_naive 512\n",
    "!./matrix_gpu_naive 1024\n",
    "!./matrix_gpu_naive 2048\n",
    "!./matrix_gpu_naive 4096\n",
    "!./matrix_gpu_naive 8192\n",
    "!./matrix_gpu_naive 16384"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cf5c47",
   "metadata": {},
   "source": [
    "## Task 4 - Optimizing CUDA Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5172ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting matrix_gpu_tiled.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile matrix_gpu_tiled.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <sys/time.h>\n",
    "#define TILE 16\n",
    "\n",
    "__global__ void matmul_tiled(float *a, float *b, float *c, int n) {\n",
    "    __shared__ float tile_a[TILE][TILE];\n",
    "    __shared__ float tile_b[TILE][TILE];\n",
    "\n",
    "    int tx = threadIdx.x;\n",
    "    int ty = threadIdx.y;\n",
    "    \n",
    "    int row = blockIdx.y * TILE + ty;\n",
    "    int col = blockIdx.x * TILE + tx;\n",
    "\n",
    "    float sum = 0.0f;\n",
    "\n",
    "    for (int m = 0; m < (n + TILE - 1) / TILE; m++) {\n",
    "        if (row < n && (m * TILE + tx) < n)\n",
    "            tile_a[ty][tx] = a[row * n + m * TILE + tx];\n",
    "        else\n",
    "            tile_a[ty][tx] = 0.0f;\n",
    "\n",
    "        if (col < n && (m * TILE + ty) < n)\n",
    "            tile_b[ty][tx] = b[(m * TILE + ty) * n + col];\n",
    "        else\n",
    "            tile_b[ty][tx] = 0.0f;\n",
    "\n",
    "        __syncthreads();\n",
    "\n",
    "        for (int k = 0; k < TILE; k++)\n",
    "            sum += tile_a[ty][k] * tile_b[k][tx];\n",
    "\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    if (row < n && col < n)\n",
    "        c[row * n + col] = sum;\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv) {\n",
    "    int n = 512;\n",
    "    if (argc > 1) {\n",
    "        n = atoi(argv[1]);\n",
    "    }\n",
    "\n",
    "    printf(\"Matrix size: %d x %d\\n\", n, n);\n",
    "\n",
    "    size_t size = n * n * sizeof(float);\n",
    "    \n",
    "    float *a = (float *)malloc(size);\n",
    "    float *b = (float *)malloc(size);\n",
    "    float *c = (float *)malloc(size);\n",
    "    \n",
    "    for (int i = 0; i < n * n; i++) {\n",
    "        a[i] = rand() % 100 / 100.0f;\n",
    "        b[i] = rand() % 100 / 100.0f;\n",
    "    }\n",
    "    \n",
    "    float *d_a, *d_b, *d_c;\n",
    "    \n",
    "    cudaMalloc(&d_a, size);\n",
    "    cudaMalloc(&d_b, size);\n",
    "    cudaMalloc(&d_c, size);\n",
    "    \n",
    "    cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n",
    "    \n",
    "    dim3 threads(16, 16);\n",
    "    dim3 blocks((n + 15) / 16, (n + 15) / 16);\n",
    "    \n",
    "    struct timeval t1, t2;\n",
    "    \n",
    "    gettimeofday(&t1, 0);\n",
    "    matmul_tiled<<<blocks, threads>>>(d_a, d_b, d_c, n);\n",
    "    cudaDeviceSynchronize();\n",
    "    gettimeofday(&t2, 0);\n",
    "    \n",
    "    double time = (1000000.0 * (t2.tv_sec - t1.tv_sec) + t2.tv_usec - t1.tv_usec) / 1000.0;\n",
    "    \n",
    "    printf(\"Time: %f ms\\n\", time);\n",
    "    \n",
    "    cudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_c);\n",
    "    \n",
    "    free(a);\n",
    "    free(b);\n",
    "    free(c);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5339f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc matrix_gpu_tiled.cu -o matrix_gpu_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b97d37c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix size: 512 x 512\n",
      "Time: 7.479584 ms\n",
      "Matrix size: 1024 x 1024\n",
      "Time: 7.357536 ms\n",
      "Matrix size: 2048 x 2048\n",
      "Time: 7.466752 ms\n",
      "Matrix size: 4096 x 4096\n",
      "Time: 7.754464 ms\n",
      "Matrix size: 8192 x 8192\n",
      "Time: 7.441408 ms\n",
      "Matrix size: 16384 x 16384\n",
      "Time: 7.374048 ms\n"
     ]
    }
   ],
   "source": [
    "!./matrix_gpu_tiled 512\n",
    "!./matrix_gpu_tiled 1024\n",
    "!./matrix_gpu_tiled 2048\n",
    "!./matrix_gpu_tiled 4096\n",
    "!./matrix_gpu_tiled 8192\n",
    "!./matrix_gpu_tiled 16384\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2417314",
   "metadata": {},
   "source": [
    "## Task 5 - Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbd1d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "python_512 = 7.81 * 1000\n",
    "python_1024 = 65.46 * 1000\n",
    "python_2048 = 839.49 * 1000\n",
    "\n",
    "cpu_512  = 0.49 * 1000\n",
    "cpu_1024 = 3.71 * 1000\n",
    "cpu_2048 = 37.63 * 1000\n",
    "\n",
    "naive_512  = 0.0125 * 1000\n",
    "naive_1024 = 0.0109 * 1000\n",
    "naive_2048 = 0.0107 * 1000\n",
    "\n",
    "tiled_512  = 0.0088 * 1000\n",
    "tiled_1024 = 0.0106 * 1000\n",
    "tiled_2048 = 0.0109 * 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a60873ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup_naive_512  = cpu_512  / naive_512\n",
    "speedup_naive_1024 = cpu_1024 / naive_1024\n",
    "speedup_naive_2048 = cpu_2048 / naive_2048\n",
    "\n",
    "speedup_tiled_512  = cpu_512  / tiled_512\n",
    "speedup_tiled_1024 = cpu_1024 / tiled_1024\n",
    "speedup_tiled_2048 = cpu_2048 / tiled_2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f257dae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f1fe150c-f8f4-4321-b058-e0d54a5568ed\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Implementation</th>\n",
       "      <th>N = 512</th>\n",
       "      <th>N = 1024</th>\n",
       "      <th>N = 2048</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPU Time (ms)</td>\n",
       "      <td>490.00</td>\n",
       "      <td>3710.00</td>\n",
       "      <td>37630.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive CUDA Time (ms)</td>\n",
       "      <td>12.50</td>\n",
       "      <td>10.90</td>\n",
       "      <td>10.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive CUDA Speedup</td>\n",
       "      <td>39.20</td>\n",
       "      <td>340.37</td>\n",
       "      <td>3516.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tiled CUDA Time (ms)</td>\n",
       "      <td>8.80</td>\n",
       "      <td>10.60</td>\n",
       "      <td>10.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tiled CUDA Speedup</td>\n",
       "      <td>55.68</td>\n",
       "      <td>350.00</td>\n",
       "      <td>3452.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1fe150c-f8f4-4321-b058-e0d54a5568ed')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-f1fe150c-f8f4-4321-b058-e0d54a5568ed button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-f1fe150c-f8f4-4321-b058-e0d54a5568ed');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         Implementation  N = 512  N = 1024  N = 2048\n",
       "0         CPU Time (ms)   490.00   3710.00  37630.00\n",
       "1  Naive CUDA Time (ms)    12.50     10.90     10.70\n",
       "2    Naive CUDA Speedup    39.20    340.37   3516.82\n",
       "3  Tiled CUDA Time (ms)     8.80     10.60     10.90\n",
       "4    Tiled CUDA Speedup    55.68    350.00   3452.29"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Implementation\": [\n",
    "        \"CPU Time (ms)\",\n",
    "        \"Naive CUDA Time (ms)\",\n",
    "        \"Naive CUDA Speedup\",\n",
    "        \"Tiled CUDA Time (ms)\",\n",
    "        \"Tiled CUDA Speedup\"\n",
    "    ],\n",
    "    \"N = 512\": [\n",
    "        cpu_512,\n",
    "        naive_512,\n",
    "        speedup_naive_512,\n",
    "        tiled_512,\n",
    "        speedup_tiled_512\n",
    "    ],\n",
    "    \"N = 1024\": [\n",
    "        cpu_1024,\n",
    "        naive_1024,\n",
    "        speedup_naive_1024,\n",
    "        tiled_1024,\n",
    "        speedup_tiled_1024\n",
    "    ],\n",
    "    \"N = 2048\": [\n",
    "        cpu_2048,\n",
    "        naive_2048,\n",
    "        speedup_naive_2048,\n",
    "        tiled_2048,\n",
    "        speedup_tiled_2048\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c55054",
   "metadata": {},
   "source": [
    "## Step 6 - Using cuBLAS Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77444d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting matrix_gpu_cublas.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile matrix_gpu_cublas.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <cublas_v2.h>\n",
    "\n",
    "int main(int argc, char **argv) {\n",
    "    int N;\n",
    "    if (argc > 1) {\n",
    "        N = atoi(argv[1]);\n",
    "    } else {\n",
    "        N = 1024; // default size\n",
    "    }\n",
    "    \n",
    "    size_t size = N * N * sizeof(float);\n",
    "\n",
    "    float *h_A = (float *)malloc(size);\n",
    "    float *h_B = (float *)malloc(size);\n",
    "    float *h_C = (float *)malloc(size);\n",
    "\n",
    "    for (int i = 0; i < N * N; i++) {\n",
    "        h_A[i] = rand() % 100 / 100.0f;\n",
    "    }\n",
    "    \n",
    "    for (int i = 0; i < N * N; i++) {\n",
    "        h_B[i] = rand() % 100 / 100.0f;\n",
    "    }\n",
    "\n",
    "    float *d_A;\n",
    "    float *d_B;\n",
    "    float *d_C;\n",
    "    \n",
    "    cudaMalloc((void**)&d_A, size);\n",
    "    cudaMalloc((void**)&d_B, size);\n",
    "    cudaMalloc((void**)&d_C, size);\n",
    "\n",
    "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    cublasHandle_t handle;\n",
    "    cublasCreate(&handle);\n",
    "\n",
    "    float alpha = 1.0f;\n",
    "    float beta  = 0.0f;\n",
    "\n",
    "    cudaEvent_t start;\n",
    "    cudaEvent_t stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    cudaEventRecord(start);\n",
    "    cublasSgemm(handle,\n",
    "                CUBLAS_OP_N, CUBLAS_OP_N,\n",
    "                N, N, N,\n",
    "                &alpha,\n",
    "                d_B, N,\n",
    "                d_A, N,\n",
    "                &beta,\n",
    "                d_C, N);\n",
    "\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "    float ms;\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    printf(\"cuBLAS SGEMM time (N=%d): %f ms\\n\", N, ms);\n",
    "\n",
    "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);   \n",
    "    volatile float sink = h_C[0];\n",
    "\n",
    "    cublasDestroy(handle);\n",
    "    \n",
    "    cudaFree(d_A);\n",
    "    cudaFree(d_B);\n",
    "    cudaFree(d_C);\n",
    "\n",
    "    free(h_A);\n",
    "    free(h_B);\n",
    "    free(h_C);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08c6bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc matrix_gpu_cublas.cu -o matrix_gpu_cublas -lcublas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d9f434f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuBLAS SGEMM time (N=512): 5.519136 ms\n",
      "cuBLAS SGEMM time (N=1024): 6.127872 ms\n",
      "cuBLAS SGEMM time (N=2048): 12.417696 ms\n"
     ]
    }
   ],
   "source": [
    "!./matrix_gpu_cublas 512\n",
    "!./matrix_gpu_cublas 1024\n",
    "!./matrix_gpu_cublas 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bedabf0",
   "metadata": {},
   "source": [
    "## Step 7 - Creating a Shared Library and Using it in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4234b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting matrix_lib.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile matrix_lib.cu\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdio.h>\n",
    "#define TILE_WIDTH 16\n",
    "\n",
    "__global__ void matrixMultiplyTiled(float *A, float *B, float *C, int N) {\n",
    "    __shared__ float ds_A[TILE_WIDTH][TILE_WIDTH];\n",
    "    __shared__ float ds_B[TILE_WIDTH][TILE_WIDTH];\n",
    "\n",
    "    int tx = threadIdx.x;\n",
    "    int ty = threadIdx.y;\n",
    "    \n",
    "    int Row = blockIdx.y * TILE_WIDTH + ty;\n",
    "    int Col = blockIdx.x * TILE_WIDTH + tx;\n",
    "\n",
    "    float Pvalue = 0.0f;\n",
    "\n",
    "    int numTiles = (N + TILE_WIDTH - 1) / TILE_WIDTH;\n",
    "    for (int m = 0; m < numTiles; ++m) {\n",
    "        int aCol = m * TILE_WIDTH + tx;\n",
    "        if (Row < N && aCol < N) {\n",
    "            ds_A[ty][tx] = A[Row * N + aCol];\n",
    "        } else {\n",
    "            ds_A[ty][tx] = 0.0f;\n",
    "        }\n",
    "\n",
    "        int bRow = m * TILE_WIDTH + ty;\n",
    "        if (Col < N && bRow < N) {\n",
    "            ds_B[ty][tx] = B[bRow * N + Col];\n",
    "        } else {\n",
    "            ds_B[ty][tx] = 0.0f;\n",
    "        }\n",
    "\n",
    "        __syncthreads();\n",
    "\n",
    "        for (int k = 0; k < TILE_WIDTH; ++k) {\n",
    "            Pvalue += ds_A[ty][k] * ds_B[k][tx];\n",
    "        }\n",
    "\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    if (Row < N && Col < N) {\n",
    "        C[Row * N + Col] = Pvalue;\n",
    "    }\n",
    "}\n",
    "\n",
    "extern \"C\" void gpu_matrix_multiply(float *h_A, float *h_B, float *h_C, int N) {\n",
    "    size_t size = N * N * sizeof(float);\n",
    "\n",
    "    float *d_A;\n",
    "    float *d_B;\n",
    "    float *d_C;\n",
    "    \n",
    "    cudaMalloc((void**)&d_A, size);\n",
    "    cudaMalloc((void**)&d_B, size);\n",
    "    cudaMalloc((void**)&d_C, size);\n",
    "\n",
    "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 block(TILE_WIDTH, TILE_WIDTH);\n",
    "    \n",
    "    int numBlocksX = (N + TILE_WIDTH - 1) / TILE_WIDTH;\n",
    "    int numBlocksY = (N + TILE_WIDTH - 1) / TILE_WIDTH;\n",
    "    dim3 grid(numBlocksX, numBlocksY);\n",
    "\n",
    "    matrixMultiplyTiled<<<grid, block>>>(d_A, d_B, d_C, N);\n",
    "    cudaDeviceSynchronize();\n",
    "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    cudaFree(d_A);\n",
    "    cudaFree(d_B);\n",
    "    cudaFree(d_C);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1be17d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -Xcompiler -fPIC -shared matrix_lib.cu -o libmatrix.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4b80565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48ed672a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with matrix size N = 512\n",
      "CUDA library time (N=512): 212.0955 milliseconds\n",
      "\n",
      "Testing with matrix size N = 1024\n",
      "CUDA library time (N=1024): 3.9580 milliseconds\n",
      "\n",
      "Testing with matrix size N = 2048\n",
      "CUDA library time (N=2048): 24.7159 milliseconds\n",
      "\n",
      "Testing with matrix size N = 4096\n",
      "CUDA library time (N=4096): 75.0914 milliseconds\n",
      "\n",
      "Testing with matrix size N = 8192\n",
      "CUDA library time (N=8192): 293.3767 milliseconds\n"
     ]
    }
   ],
   "source": [
    "lib = ctypes.cdll.LoadLibrary(\"./libmatrix.so\")\n",
    "lib.gpu_matrix_multiply.argtypes = [\n",
    "    np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
    "    np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
    "    np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
    "    ctypes.c_int\n",
    "]\n",
    "\n",
    "N = 512\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"\\nTesting with matrix size N = {N}\")\n",
    "    \n",
    "    A = np.random.rand(N, N).astype(np.float32)\n",
    "    B = np.random.rand(N, N).astype(np.float32)\n",
    "    C = np.zeros((N, N), dtype=np.float32)\n",
    "    \n",
    "    start = time.time()\n",
    "    lib.gpu_matrix_multiply(A.ravel(), B.ravel(), C.ravel(), N)\n",
    "    end = time.time()\n",
    "    elapsed_time = end - start\n",
    "    \n",
    "    print(f\"CUDA library time (N={N}): {elapsed_time * 1000:.4f} milliseconds\")\n",
    "    \n",
    "    N = N * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5bccb0",
   "metadata": {},
   "source": [
    "## Step 8 - Adding Custom Functions to the Shared Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa705c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting conv_gpu.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile conv_gpu.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void convolution2D_GPU(\n",
    "    unsigned char *image,\n",
    "    int *kernel,\n",
    "    int *output,\n",
    "    int width,\n",
    "    int height\n",
    ") {\n",
    "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "\n",
    "    if (x >= width || y >= height) return;\n",
    "\n",
    "    int sum = 0;\n",
    "    int k = 1;  // 3x3 kernel radius\n",
    "\n",
    "    for (int ky = -k; ky <= k; ky++) {\n",
    "        for (int kx = -k; kx <= k; kx++) {\n",
    "            int ix = x + kx;\n",
    "            int iy = y + ky;\n",
    "            if (ix >= 0 && ix < width && iy >= 0 && iy < height) {\n",
    "                int pixel = image[iy * width + ix];\n",
    "                int weight = kernel[(ky + k) * 3 + (kx + k)];\n",
    "                sum += pixel * weight;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    output[y * width + x] = sum;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int width = 512;\n",
    "    int height = 512;\n",
    "    size_t img_size = width * height * sizeof(unsigned char);\n",
    "    size_t out_size = width * height * sizeof(int);\n",
    "\n",
    "    unsigned char *h_img = (unsigned char*)malloc(img_size);\n",
    "    int *h_out = (int*)malloc(out_size);\n",
    "\n",
    "    int h_kernel[9] = {\n",
    "        -1, -1, -1,\n",
    "        -1,  8, -1,\n",
    "        -1, -1, -1\n",
    "    };\n",
    "\n",
    "    for (int i = 0; i < width * height; i++)\n",
    "        h_img[i] = rand() % 256;\n",
    "\n",
    "    unsigned char *d_img;\n",
    "    int *d_kernel, *d_out;\n",
    "\n",
    "    cudaMalloc(&d_img, img_size);\n",
    "    cudaMalloc(&d_kernel, 9 * sizeof(int));\n",
    "    cudaMalloc(&d_out, out_size);\n",
    "\n",
    "    cudaMemcpy(d_img, h_img, img_size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_kernel, h_kernel, 9 * sizeof(int), cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 block(16, 16);\n",
    "    dim3 grid((width + 15) / 16, (height + 15) / 16);\n",
    "\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "\n",
    "    cudaEventRecord(start);\n",
    "    convolution2D_GPU<<<grid, block>>>(d_img, d_kernel, d_out, width, height);\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "\n",
    "    float ms;\n",
    "    cudaEventElapsedTime(&ms, start, stop);\n",
    "    printf(\"CUDA convolution time: %f ms\\n\", ms);\n",
    "\n",
    "    cudaMemcpy(h_out, d_out, out_size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    cudaFree(d_img);\n",
    "    cudaFree(d_kernel);\n",
    "    cudaFree(d_out);\n",
    "    free(h_img);\n",
    "    free(h_out);\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c88f175b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc conv_gpu.cu -o conv_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d989833d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA convolution time: 7.379104 ms\n"
     ]
    }
   ],
   "source": [
    "!./conv_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32063245",
   "metadata": {},
   "source": [
    "#### Adding and Using the Convolution to your Custom Python Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fa9ad25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting conv_lib.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile conv_lib.cu\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "__global__ void convolution2D_GPU(\n",
    "    unsigned char *image,\n",
    "    int *kernel,\n",
    "    int *output,\n",
    "    int width,\n",
    "    int height\n",
    ") {\n",
    "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "\n",
    "    if (x >= width || y >= height) return;\n",
    "\n",
    "    int sum = 0;\n",
    "    int k = 1; // 3x3 kernel radius\n",
    "\n",
    "    for (int ky = -k; ky <= k; ky++) {\n",
    "        for (int kx = -k; kx <= k; kx++) {\n",
    "            int ix = x + kx;\n",
    "            int iy = y + ky;\n",
    "\n",
    "            if (ix >= 0 && ix < width && iy >= 0 && iy < height) {\n",
    "                int pixel = image[iy * width + ix];\n",
    "                int weight = kernel[(ky + k) * 3 + (kx + k)];\n",
    "                sum += pixel * weight;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    output[y * width + x] = sum;\n",
    "}\n",
    "\n",
    "extern \"C\" void gpu_convolution(\n",
    "    unsigned char *h_image,\n",
    "    int *h_kernel,\n",
    "    int *h_output,\n",
    "    int width,\n",
    "    int height\n",
    ") {\n",
    "    size_t img_size = width * height * sizeof(unsigned char);\n",
    "    size_t out_size = width * height * sizeof(int);\n",
    "\n",
    "    unsigned char *d_image;\n",
    "    int *d_kernel;\n",
    "    int *d_output;\n",
    "\n",
    "    cudaMalloc((void**)&d_image, img_size);\n",
    "    cudaMalloc((void**)&d_kernel, 9 * sizeof(int));\n",
    "    cudaMalloc((void**)&d_output, out_size);\n",
    "\n",
    "    cudaMemcpy(d_image, h_image, img_size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_kernel, h_kernel, 9 * sizeof(int), cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 block(16, 16);\n",
    "    dim3 grid((width + 15) / 16, (height + 15) / 16);\n",
    "\n",
    "    convolution2D_GPU<<<grid, block>>>(d_image, d_kernel, d_output, width, height);\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    cudaMemcpy(h_output, d_output, out_size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    cudaFree(d_image);\n",
    "    cudaFree(d_kernel);\n",
    "    cudaFree(d_output);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37615c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -Xcompiler -fPIC -shared matrix_lib.cu conv_lib.cu -o libmatrix.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03f1861a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000000000000b0e5 T gpu_convolution\n"
     ]
    }
   ],
   "source": [
    "!nm -D libmatrix.so | grep gpu_convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1cf69b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA convolution time: 9.2390 ms\n"
     ]
    }
   ],
   "source": [
    "if './libmatrix.so' in sys.modules:\n",
    "    del sys.modules['./libmatrix.so']\n",
    "\n",
    "lib_path = os.path.abspath('./libmatrix.so')\n",
    "lib = ctypes.CDLL(lib_path)\n",
    "\n",
    "gpu_conv_func = lib.gpu_convolution\n",
    "gpu_conv_func.argtypes = [\n",
    "    np.ctypeslib.ndpointer(dtype=np.uint8, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
    "    np.ctypeslib.ndpointer(dtype=np.int32, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
    "    np.ctypeslib.ndpointer(dtype=np.int32, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
    "    ctypes.c_int,\n",
    "    ctypes.c_int\n",
    "]\n",
    "\n",
    "width = 512\n",
    "height = 512\n",
    "\n",
    "image = np.random.randint(0, 256, size=(height, width), dtype=np.uint8)\n",
    "\n",
    "kernel = np.array([\n",
    "    -1, -1, -1,\n",
    "    -1,  8, -1,\n",
    "    -1, -1, -1\n",
    "], dtype=np.int32)\n",
    "\n",
    "output = np.zeros((height, width), dtype=np.int32)\n",
    "\n",
    "start = time.time()\n",
    "gpu_conv_func(\n",
    "    image.ravel(),\n",
    "    kernel,\n",
    "    output.ravel(),\n",
    "    width,\n",
    "    height\n",
    ")\n",
    "end = time.time()\n",
    "\n",
    "print(f\"CUDA convolution time: {(end - start) * 1000:.4f} ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
